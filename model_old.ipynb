{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfmZXEAKYwfU"
      },
      "source": [
        "# ‚Å†Autonomous Object Detection System\n",
        "Problem Statement\n",
        "Object detection is crucial for autonomous systems such as self-driving cars and surveillance.\n",
        "This project builds a real-time object detection system using deep learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install opencv-python matplotlib kagglehub python-dotenv jupyter ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip uninstall -y numpy\n",
        "%pip install \"numpy>=1.23.5,<2\"\n",
        "%pip install tensorflow-macos tensorflow-metal tensorflow-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQUsxhgzYzO6"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aii9M_cmY1VT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import os\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZE9lQsNO5AH"
      },
      "source": [
        "Clearing cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3nlv9yIO6n_",
        "outputId": "d0b726e6-e32b-4081-efa4-c26a98bea3a1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlFdGeX7MU14"
      },
      "source": [
        "GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeMi0kVpMcPj",
        "outputId": "aac5a421-7592-4d65-b87c-77a055017a3d"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    print(\"Using gpu: \", gpus)\n",
        "else:\n",
        "    print(\"no gpu found using cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS0MqhrrN5QD"
      },
      "source": [
        "Shit we will be using\n",
        "- Framework: Tensorflow\n",
        "- Model: SSD MobileNet\n",
        "- Dataset: COCO128\n",
        "\n",
        "Resources used\n",
        "- Youtube: codebasics, DeepBeaning\n",
        "- v7labs.com\n",
        "- and ofcourse heavy use of ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LudhCNSAfZzF"
      },
      "source": [
        "Defining the classes by COCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8rZztaIfc_P"
      },
      "outputs": [],
      "source": [
        "COCO_CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
        "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
        "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
        "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
        "    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',\n",
        "    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZPZZwNK5Ln2"
      },
      "source": [
        "Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYFAaS5u5QFS"
      },
      "outputs": [],
      "source": [
        "GRID_SIZE = 13\n",
        "BOXES_PER_CELL = 3\n",
        "NUM_CLASSES = 80\n",
        "INPUT_SIZE = 416\n",
        "CELL_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCPcUgkDOyrU"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE7wjqRgO6yd",
        "outputId": "c8593a3d-33e4-4e59-fe87-5dfa665c9240"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"ultralytics/coco128\")\n",
        "\n",
        "print(path)\n",
        "print(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2qAFDGPTgZb"
      },
      "outputs": [],
      "source": [
        "IMG_DIR = os.path.join(path, \"coco128\",\"images\", \"train2017\")\n",
        "LABEL_DIR = os.path.join(path, \"coco128\",\"labels\",\"train2017\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKAuo7AWTxkq",
        "outputId": "932aefa2-83ca-4096-a51b-a729f505f186"
      },
      "outputs": [],
      "source": [
        "print(\"images: \",len(os.listdir(IMG_DIR)))\n",
        "print(\"labels: \",len(os.listdir(LABEL_DIR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqCyUwSSXXYy"
      },
      "source": [
        "Loading the image and label in sorted pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvXLaz4OXGT1"
      },
      "outputs": [],
      "source": [
        "image_files = sorted(os.listdir(IMG_DIR))\n",
        "label_files = sorted(os.listdir(LABEL_DIR))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSspEvwAY19r"
      },
      "source": [
        "Loading an image and drawing bounding boxes around it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNEjyF7XZBIB"
      },
      "outputs": [],
      "source": [
        "def load_image_label(index):\n",
        "  # picking nth image\n",
        "  image_name = image_files[index]\n",
        "  label_name = label_files[index]\n",
        "\n",
        "  # loading the image\n",
        "  img_path = os.path.join(IMG_DIR, image_name)\n",
        "  img = cv2.imread(img_path)\n",
        "\n",
        "  if img is None:\n",
        "    print(f\"no image at {img_path}\")\n",
        "    return None, None, None, None, None,\n",
        "\n",
        "  height, width, channels = img.shape\n",
        "\n",
        "  # reading the label file\n",
        "  with open(os.path.join(LABEL_DIR, label_name), 'r') as f:\n",
        "    labels = f.readlines()\n",
        "\n",
        "  return image_name, img, labels, height, width\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2FhIINqblXT"
      },
      "outputs": [],
      "source": [
        "def label_to_bb(label, width, height):\n",
        "  parts_string = label.split()\n",
        "  parts = [float(x) for x in parts_string]\n",
        "\n",
        "  # convert label data to data for bb in pixels\n",
        "  class_id = int(parts[0])\n",
        "  x_center = float(parts[1]) * width\n",
        "  y_center = float(parts[2])*height\n",
        "  box_width = float(parts[3])*width\n",
        "  box_height = float(parts[4])*height\n",
        "\n",
        "  # convert center coord to corner coord to draw bb\n",
        "  # top left\n",
        "  x1 = x_center-(box_width/2)\n",
        "  y1 = y_center-(box_height/2)\n",
        "  # bottom right\n",
        "  x2 = x_center+(box_width/2)\n",
        "  y2 = y_center+(box_height/2)\n",
        "\n",
        "  return class_id, int(x1), int(y1), int(x2), int(y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v12_Wp18ePVc"
      },
      "outputs": [],
      "source": [
        "def draw_bb(index):\n",
        "  image_name, img, labels, height, width = load_image_label(index)\n",
        "\n",
        "  img_bb = img.copy()\n",
        "\n",
        "  for label in labels:\n",
        "    class_id, x1, y1, x2, y2 = label_to_bb(label, width, height)\n",
        "    class_name = COCO_CLASSES[class_id]\n",
        "\n",
        "    # random color for the bb\n",
        "    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "\n",
        "    img_bb = cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n",
        "    img_bb = cv2.putText(img_bb, class_name, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.imshow(cv2.cvtColor(img_bb, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"{image_name} - {len(labels)} objects\")\n",
        "  plt.show()\n",
        "\n",
        "  return img_bb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMw_EJ4Pj-MO"
      },
      "source": [
        "Preprocessing Image and Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P01yZyTskhWd"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img):\n",
        "  resize_img = cv2.resize(img, (INPUT_SIZE,INPUT_SIZE), interpolation=cv2.INTER_LINEAR)\n",
        "  normalized_img = resize_img / 255.0\n",
        "\n",
        "  return normalized_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99JOkz52qpSb"
      },
      "outputs": [],
      "source": [
        "def preprocess_labels(labels):\n",
        "    processed = []\n",
        "    for label in labels:\n",
        "        parts = label.strip().split()\n",
        "        # class_id, x_center, y_center, width, height\n",
        "        parsed = [float(parts[0])] + [float(x) for x in parts[1:]]\n",
        "        processed.append(parsed)\n",
        "\n",
        "    return processed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_yDj8KkkuCc"
      },
      "source": [
        "Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfbeENsGl7BV"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "  preprocessed_images = []\n",
        "  preprocessed_labels = []\n",
        "\n",
        "  print(f\"processing {len(image_files)} images...\")\n",
        "\n",
        "  for i in range(len(image_files)):\n",
        "    image_name, img, labels, height, width = load_image_label(i)\n",
        "\n",
        "    preprocessed_img = preprocess_image(img)\n",
        "    processed_labels = preprocess_labels(labels)\n",
        "\n",
        "    preprocessed_images.append(preprocessed_img)\n",
        "    preprocessed_labels.append(processed_labels)\n",
        "\n",
        "  print(f\"Total images: {len(preprocessed_images)}\")\n",
        "  print(f\"Total labels: {len(preprocessed_labels)}\")\n",
        "\n",
        "  return preprocessed_images, preprocessed_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0scuu_2MrAth"
      },
      "outputs": [],
      "source": [
        "def train_val_split(images, labels, train_ratio=0.8):\n",
        "    split_index = int(len(images) * train_ratio)\n",
        "\n",
        "    # split images\n",
        "    train_images = images[:split_index]\n",
        "    val_images = images[split_index:]\n",
        "\n",
        "    # split labels\n",
        "    train_labels = labels[:split_index]\n",
        "    val_labels = labels[split_index:]\n",
        "\n",
        "    # verification\n",
        "    print(f\"Training: {len(train_images)} images, {len(train_labels)} labels\")\n",
        "    print(f\"Validation: {len(val_images)} images, {len(val_labels)} labels\")\n",
        "\n",
        "    # safety checks\n",
        "    assert len(train_images) == len(train_labels), \"Train size mismatch!\"\n",
        "    assert len(val_images) == len(val_labels), \"Val size mismatch!\"\n",
        "\n",
        "    return train_images, train_labels, val_images, val_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjdRIj8a2xnV"
      },
      "source": [
        "Grid based label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uTIR2N7218l"
      },
      "outputs": [],
      "source": [
        "def prepare_grid_labels(labels):\n",
        "  y=[]\n",
        "\n",
        "  for label in labels:\n",
        "    # empty grid\n",
        "    grid = np.zeros((GRID_SIZE,GRID_SIZE,BOXES_PER_CELL,NUM_CLASSES+5))\n",
        "    # no of bb per grid\n",
        "    cell_bb_count = np.zeros((GRID_SIZE,GRID_SIZE), dtype=int)\n",
        "\n",
        "    for obj in label:\n",
        "      class_id = int(obj[0])\n",
        "      x_center = float(obj[1])\n",
        "      y_center = float(obj[2])\n",
        "      width = float(obj[3])\n",
        "      height = float(obj[4])\n",
        "\n",
        "      # grid the object is in\n",
        "      grid_x=int(x_center*GRID_SIZE)\n",
        "      grid_y=int(y_center*GRID_SIZE)\n",
        "      # if coord is 1 then the grid becomes 13 and bam out of bounds error\n",
        "      grid_x=min(grid_x,GRID_SIZE-1)\n",
        "      grid_y=min(grid_y,GRID_SIZE-1)\n",
        "\n",
        "      # checking whether the grid has room for another bb\n",
        "      cell_count_current = cell_bb_count[grid_y,grid_x]\n",
        "\n",
        "      if cell_count_current>=BOXES_PER_CELL:\n",
        "        # if max(=3) objects reached then skip object\n",
        "        print(f\"({grid_y,{grid_x}}) full, skipping obejct\")\n",
        "        continue\n",
        "\n",
        "      # calculating where in the cell the object is instead of the whole ass image\n",
        "      # absolute pos in form of grid\n",
        "      x_abs=x_center*GRID_SIZE\n",
        "      y_abs=y_center*GRID_SIZE\n",
        "      # pos within the cell\n",
        "      x_rel=x_abs-grid_x\n",
        "      y_rel=y_abs-grid_y\n",
        "\n",
        "      # using one hot encoding to not confuse this dumb aah model\n",
        "      class_one_hot = np.zeros(NUM_CLASSES)\n",
        "      class_one_hot[class_id] = 1.0\n",
        "\n",
        "      bbox = np.array([x_rel,y_rel,width,height])\n",
        "      # if confidence 1 then object there\n",
        "      # putting confidence manually so the model can filter empty cells\n",
        "      confidence = np.array([1.0])\n",
        "\n",
        "      label = np.concatenate([class_one_hot,bbox,confidence])\n",
        "      # assinging that label to the grid it corresponds to\n",
        "      grid[grid_y, grid_x, cell_count_current]=label\n",
        "      # mark that grid used\n",
        "      cell_bb_count[grid_y,grid_x] += 1\n",
        "\n",
        "    y.append(grid)\n",
        "\n",
        "  return np.array(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aucufZUM8ad7"
      },
      "source": [
        "Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7xEl81n8b5I"
      },
      "outputs": [],
      "source": [
        "def grid_detection_loss(y_true, y_pred):\n",
        "  # will combine three losses\n",
        "  # is it the right object, is the box in the right place, is there an object\n",
        "\n",
        "  # seperating the classes -> 0-79: class, 80-83: bb data, 84: confidence\n",
        "  y_true_class = y_true[..., :NUM_CLASSES]\n",
        "  y_pred_class = y_pred[..., :NUM_CLASSES]\n",
        "  y_true_bb = y_true[..., NUM_CLASSES:NUM_CLASSES+4]\n",
        "  y_pred_bb = y_pred[..., NUM_CLASSES:NUM_CLASSES+4]\n",
        "  y_true_conf = y_true[..., -1:]\n",
        "  y_pred_conf = y_pred[..., -1:]\n",
        "\n",
        "  # having a mask matrix same as conf matrix which we can multiply later so that empty grid would not be calculated\n",
        "  obj_mask = y_true_conf\n",
        "\n",
        "  class_loss = keras.losses.categorical_crossentropy(y_true_class, y_pred_class)\n",
        "  class_loss = class_loss * tf.squeeze(obj_mask, axis=-1)\n",
        "  class_loss = tf.reduce_mean(class_loss)\n",
        "\n",
        "  bb_loss = tf.reduce_mean(tf.square(y_true_bb - y_pred_bb), axis=-1, keepdims=True)\n",
        "  bb_loss = bb_loss * obj_mask\n",
        "  bb_loss = tf.reduce_mean(bb_loss)\n",
        "\n",
        "  conf_loss = keras.losses.binary_crossentropy(y_true_conf, y_pred_conf)\n",
        "  conf_loss = tf.reduce_mean(conf_loss)\n",
        "\n",
        "  # adding weights\n",
        "  total_loss = 5.0 * class_loss + 3.0 * bb_loss + 1.0 * conf_loss\n",
        "\n",
        "  return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6APWob3RsH2s"
      },
      "source": [
        "Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvVv3ADcsI_x",
        "outputId": "708ddde4-1789-4357-8cd5-a758f90381fe"
      },
      "outputs": [],
      "source": [
        "backbone = keras.applications.MobileNetV2(\n",
        "    input_shape = (INPUT_SIZE,INPUT_SIZE,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    alpha=1.0\n",
        ")\n",
        "\n",
        "backbone.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHmifKDNuv2-"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(INPUT_SIZE,INPUT_SIZE,3))\n",
        "\n",
        "layers = keras.layers\n",
        "\n",
        "x = backbone(inputs, training=False)\n",
        "x = layers.Conv2D(512, (3, 3), padding='same', activation='relu',\n",
        "                  kernel_initializer='he_normal')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "x = layers.Conv2D(256, (3, 3), padding='same', activation='relu',\n",
        "                  kernel_initializer='he_normal')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "x = layers.Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "                  kernel_initializer='he_normal')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "num_outputs = BOXES_PER_CELL * (NUM_CLASSES + 5)\n",
        "outputs = layers.Conv2D(num_outputs, (1, 1), activation='sigmoid',\n",
        "                               kernel_initializer='glorot_uniform',\n",
        "                               bias_initializer='zeros')(x)\n",
        "outputs = layers.Reshape((GRID_SIZE, GRID_SIZE, BOXES_PER_CELL, NUM_CLASSES + 5))(outputs)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "qzH_2AE_1Ptc",
        "outputId": "d7200fda-e2c6-45bb-f6fd-11ad69cabc5f"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8lFdfRFVOcj"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS3cTn5QVQPo",
        "outputId": "50bce2c3-6848-41a2-c4d2-ac5b3bfbe5d6"
      },
      "outputs": [],
      "source": [
        "all_images, all_labels = create_dataset()\n",
        "print(f\"Dataset created: {len(all_images)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPYpe3OIVhZV"
      },
      "source": [
        "Train val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q019T3JIVjWz",
        "outputId": "7624773f-625e-4079-c224-52902eeb8a40"
      },
      "outputs": [],
      "source": [
        "train_imgs, train_labels, val_imgs, val_labels = train_val_split(all_images, all_labels, train_ratio=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjMCt4ajVygn"
      },
      "source": [
        "Convert to grid format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyOJVsfsWA8U",
        "outputId": "6e3b907e-995f-4786-819c-89511ea55409"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(train_imgs)\n",
        "x_val = np.array(val_imgs)\n",
        "y_train=prepare_grid_labels(train_labels)\n",
        "y_val=prepare_grid_labels(val_labels)\n",
        "\n",
        "print(f\"x_train: {x_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ6C2Q9GWqxx"
      },
      "source": [
        "Compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7dVq6YJWr03"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(\n",
        "        learning_rate=0.0005,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-07),\n",
        "    loss=grid_detection_loss,\n",
        "    metrics=['mae']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6hoSlyXW6Kk"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34OFtAFMW71W"
      },
      "outputs": [],
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl65DaUuW_Oj",
        "outputId": "86e8442d-a37b-4449-ef05-606a2c91196e"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ0X4xEWXFrT"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtLQlQ2qXGvR",
        "outputId": "05aab01c-b5fa-4f61-b6fb-c0714a3d9a61"
      },
      "outputs": [],
      "source": [
        "model.save('yolo_type_shi.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnpQA9b0XNn5"
      },
      "source": [
        "Plots and shit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "KWjHOjG4XPNd",
        "outputId": "9130ee03-cda7-4202-ce82-eda1f2c7c4e8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# MAE plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Training MAE')\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('Bounding Box Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DERhTkqgupw-"
      },
      "source": [
        "Testing shit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVo6v17ruq-9"
      },
      "outputs": [],
      "source": [
        "def decode_predictions(predictions, conf_threshold=0.3):\n",
        "  boxes=[]\n",
        "  classes=[]\n",
        "  confidences=[]\n",
        "\n",
        "  for grid_y in range(GRID_SIZE):\n",
        "        for grid_x in range(GRID_SIZE):\n",
        "            for box_idx in range(BOXES_PER_CELL):\n",
        "                pred = predictions[grid_y, grid_x, box_idx]\n",
        "\n",
        "                confidence = pred[-1]\n",
        "\n",
        "                if confidence < conf_threshold:\n",
        "                    continue\n",
        "\n",
        "                # getting the class with the highest probability\n",
        "                class_probs = pred[:NUM_CLASSES]\n",
        "                class_id = np.argmax(class_probs)\n",
        "                class_confidence = class_probs[class_id] * confidence\n",
        "\n",
        "                if class_confidence < conf_threshold:\n",
        "                    continue\n",
        "\n",
        "                # bb coords\n",
        "                x_rel = pred[NUM_CLASSES]\n",
        "                y_rel = pred[NUM_CLASSES + 1]\n",
        "                width = pred[NUM_CLASSES + 2]\n",
        "                height = pred[NUM_CLASSES + 3]\n",
        "\n",
        "                # pos in whole img\n",
        "                x_center = (grid_x + x_rel) / GRID_SIZE\n",
        "                y_center = (grid_y + y_rel) / GRID_SIZE\n",
        "\n",
        "                boxes.append([class_id, x_center, y_center, width, height])\n",
        "                confidences.append(class_confidence)\n",
        "\n",
        "  return boxes, confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nazk_ZpxEv4"
      },
      "outputs": [],
      "source": [
        "def test_image(model, index, conf_threshold=0.3):\n",
        "  img_name, img, labels, height, width = load_image_label(index)\n",
        "\n",
        "  preproccessed_img=preprocess_image(img)\n",
        "  # model expects batch dimension so adding that\n",
        "  input_batch = np.expand_dims(preproccessed_img, axis=0)\n",
        "\n",
        "  predictions = model.predict(input_batch, verbose=0)[0]\n",
        "\n",
        "  boxes, confidences = decode_predictions(predictions, conf_threshold=conf_threshold)\n",
        "\n",
        "  img_pred=img.copy()\n",
        "  # each detected box's label is formatted into string\n",
        "  for box, conf in zip(boxes, confidences):\n",
        "    label_string = f\"{int(box[0])} {box[1]} {box[2]} {box[3]} {box[4]}\"\n",
        "    class_id, x1, y1, x2, y2 = label_to_bb(label_string, width, height)\n",
        "\n",
        "    class_name = COCO_CLASSES[class_id]\n",
        "    color = (0, 255, 0)  # green->prediction\n",
        "\n",
        "    # drawing bb\n",
        "    cv2.rectangle(img_pred, (x1, y1), (x2, y2), color, 2)\n",
        "    # put a label on that thang\n",
        "    label_text = f\"{class_name}: {conf:.2f}\"\n",
        "    cv2.putText(img_pred, label_text, (x1, y1 - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # display that thang\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"{img_name} - {len(boxes)} objects detected\")\n",
        "  plt.show()\n",
        "\n",
        "  print(f\"\\nImage: {img_name}\")\n",
        "  print(f\"Detected {len(boxes)} objects:\")\n",
        "  for box, conf in zip(boxes, confidences):\n",
        "      class_id = int(box[0])\n",
        "      print(f\"  - {COCO_CLASSES[class_id]}: {conf:.3f}\")\n",
        "\n",
        "  return img_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTjX3qSc5Yjd"
      },
      "source": [
        "Finally test that thang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mr8CdWT95bDi",
        "outputId": "b0834e0a-5664-447c-a768-50335dbb0fac"
      },
      "outputs": [],
      "source": [
        "test_image(model, 23, conf_threshold=0.35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing it using custom images inside a folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_custom_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not load image: {img_path}\")\n",
        "    height, width, _ = img.shape\n",
        "    return img, height, width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_custom_image(model, img_path, conf_threshold=0.3):\n",
        "    img, height, width = load_custom_image(img_path)\n",
        "\n",
        "    preprocessed_img = preprocess_image(img)\n",
        "    input_batch = np.expand_dims(preprocessed_img, axis=0)\n",
        "\n",
        "    predictions = model.predict(input_batch, verbose=0)[0]\n",
        "    boxes, confidences = decode_predictions(predictions, conf_threshold)\n",
        "\n",
        "    img_pred = img.copy()\n",
        "\n",
        "    for box, conf in zip(boxes, confidences):\n",
        "        label_string = f\"{int(box[0])} {box[1]} {box[2]} {box[3]} {box[4]}\"\n",
        "        class_id, x1, y1, x2, y2 = label_to_bb(label_string, width, height)\n",
        "\n",
        "        class_name = COCO_CLASSES[class_id]\n",
        "        color = (0, 255, 0)\n",
        "\n",
        "        cv2.rectangle(img_pred, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(\n",
        "            img_pred,\n",
        "            f\"{class_name}: {conf:.2f}\",\n",
        "            (x1, y1 - 10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.5,\n",
        "            color,\n",
        "            2\n",
        "        )\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"{os.path.basename(img_path)} ‚Äî {len(boxes)} objects detected\")\n",
        "    plt.show()\n",
        "\n",
        "    return img_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_images_in_folder(model, folder_path=\"test\", conf_threshold=0.3):\n",
        "    images = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "    ])\n",
        "\n",
        "    print(f\"Found {len(images)} images in '{folder_path}'\")\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        print(f\"\\nüñºÔ∏è Testing: {img_name}\")\n",
        "        test_custom_image(model, img_path, conf_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_images_in_folder(model, \"test\", conf_threshold=0.35)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.10.18)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
